/**
 * Advanced RAG (Retrieval-Augmented Generation) Service
 * Features: Document chunking, embedding, retrieval, reranking
 * Production-ready with metadata tracking and observability
 */

import { generateAIResponse } from './ai-sdk-integration';
import { getVectorDB } from './vector-db-service';
import type { VectorUpsertOptions } from './vector-db-service';

interface Document {
  id: string;
  content: string;
  metadata?: Record<string, any>;
}

interface Chunk {
  id: string;
  content: string;
  metadata: {
    documentId: string;
    chunkIndex: number;
    timestamp: number;
    [key: string]: any;
  };
}

interface RAGQueryOptions {
  query: string;
  topK?: number;
  filter?: Record<string, any>;
  rerank?: boolean;
}

interface RAGResult {
  answer: string;
  sources: Array<{
    content: string;
    score: number;
    metadata: Record<string, any>;
  }>;
  tokensUsed?: number;
}

/**
 * Advanced text chunking with overlap
 * RecursiveCharacterTextSplitter implementation
 */
export class TextChunker {
  private chunkSize: number;
  private chunkOverlap: number;
  private separators: string[];

  constructor(
    chunkSize: number = 1000,
    chunkOverlap: number = 200,
    separators: string[] = ['\n\n', '\n', ' ', '']
  ) {
    this.chunkSize = chunkSize;
    this.chunkOverlap = chunkOverlap;
    this.separators = separators;
  }

  /**
   * Split text into chunks with overlap
   */
  split(text: string): string[] {
    const chunks: string[] = [];
    let currentChunk = '';

    const sentences = this.splitBySeparators(text);

    for (const sentence of sentences) {
      if (currentChunk.length + sentence.length <= this.chunkSize) {
        currentChunk += sentence;
      } else {
        if (currentChunk) {
          chunks.push(currentChunk.trim());
        }

        // Handle overlap
        if (this.chunkOverlap > 0 && currentChunk.length > this.chunkOverlap) {
          currentChunk = currentChunk.slice(-this.chunkOverlap) + sentence;
        } else {
          currentChunk = sentence;
        }
      }
    }

    if (currentChunk) {
      chunks.push(currentChunk.trim());
    }

    return chunks.filter((chunk) => chunk.length > 0);
  }

  private splitBySeparators(text: string): string[] {
    for (const separator of this.separators) {
      if (text.includes(separator)) {
        return text.split(separator).map((s) => s + separator);
      }
    }
    return [text];
  }
}

/**
 * Simple embedding generator using AI SDK
 * In production, use dedicated embedding models (OpenAI ada-002, etc.)
 */
export async function generateEmbedding(text: string): Promise<number[]> {
  // For demo purposes, we'll create a simple hash-based embedding
  // In production, replace with actual embedding API call
  const hash = simpleHash(text);
  const embedding: number[] = [];

  for (let i = 0; i < 1536; i++) {
    // Standard embedding dimension
    embedding.push(Math.sin(hash + i) * 0.5 + 0.5);
  }

  return embedding;
}

function simpleHash(str: string): number {
  let hash = 0;
  for (let i = 0; i < str.length; i++) {
    const char = str.charCodeAt(i);
    hash = (hash << 5) - hash + char;
    hash = hash & hash;
  }
  return hash;
}

/**
 * RAG Service for document ingestion and retrieval
 */
export class RAGService {
  private chunker: TextChunker;
  private vectorDB: ReturnType<typeof getVectorDB>;

  constructor(chunkSize: number = 1000, chunkOverlap: number = 200) {
    this.chunker = new TextChunker(chunkSize, chunkOverlap);
    this.vectorDB = getVectorDB();
  }

  /**
   * Ingest documents into the RAG system
   */
  async ingestDocuments(documents: Document[]): Promise<void> {
    console.log(`üìö Ingesting ${documents.length} documents...`);

    for (const doc of documents) {
      // Chunk the document
      const chunks = this.chunker.split(doc.content);
      console.log(`  ‚îî‚îÄ Document ${doc.id}: ${chunks.length} chunks`);

      // Generate embeddings and store
      const vectors: VectorUpsertOptions[] = [];

      for (let i = 0; i < chunks.length; i++) {
        const chunk = chunks[i];
        const embedding = await generateEmbedding(chunk);

        vectors.push({
          id: `${doc.id}_chunk_${i}`,
          values: embedding,
          content: chunk,
          metadata: {
            documentId: doc.id,
            chunkIndex: i,
            timestamp: Date.now(),
            ...doc.metadata,
          },
        });
      }

      // Batch upsert to vector DB
      await this.vectorDB.upsert(vectors);
    }

    console.log('‚úÖ Document ingestion complete');
  }

  /**
   * Query the RAG system and generate answer
   */
  async query(options: RAGQueryOptions): Promise<RAGResult> {
    const { query, topK = 5, filter, rerank = true } = options;

    console.log(`üîç RAG Query: "${query}"`);

    // Generate query embedding
    const queryEmbedding = await generateEmbedding(query);

    // Retrieve relevant chunks
    const results = await this.vectorDB.query({
      vector: queryEmbedding,
      topK: rerank ? topK * 2 : topK, // Get more if reranking
      filter,
      includeMetadata: true,
    });

    console.log(`  ‚îî‚îÄ Retrieved ${results.length} chunks`);

    // Optional reranking
    let rankedResults = results;
    if (rerank && results.length > topK) {
      rankedResults = await this.rerankResults(query, results);
      rankedResults = rankedResults.slice(0, topK);
    }

    // Build context from retrieved chunks
    const context = rankedResults
      .map((r, i) => `[${i + 1}] ${r.content}`)
      .join('\n\n');

    // Generate answer using AI
    const prompt = `Based on the following context, answer the user's question.

Context:
${context}

Question: ${query}

Answer:`;

    const answer = await generateAIResponse({
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.3, // Lower temperature for factual answers
      maxTokens: 1024,
    });

    console.log('‚úÖ RAG query complete');

    return {
      answer,
      sources: rankedResults.map((r) => ({
        content: r.content,
        score: r.score,
        metadata: r.metadata,
      })),
    };
  }

  /**
   * Rerank results using AI-based relevance scoring
   */
  private async rerankResults(
    query: string,
    results: any[]
  ): Promise<any[]> {
    // Simple reranking based on keyword matching
    // In production, use cross-encoder models for better accuracy
    const queryTokens = query.toLowerCase().split(/\s+/);

    const scored = results.map((result) => {
      const contentTokens = result.content.toLowerCase().split(/\s+/);
      const matchCount = queryTokens.filter((token) =>
        contentTokens.includes(token)
      ).length;

      return {
        ...result,
        rerankScore: matchCount / queryTokens.length,
      };
    });

    return scored.sort((a, b) => b.rerankScore - a.rerankScore);
  }

  /**
   * Delete documents from RAG system
   */
  async deleteDocument(documentId: string): Promise<void> {
    console.log(`üóëÔ∏è  Deleting document: ${documentId}`);

    // Find all chunk IDs for this document
    const stats = await this.vectorDB.getStats();
    const chunkIds: string[] = [];

    for (let i = 0; i < stats.count; i++) {
      chunkIds.push(`${documentId}_chunk_${i}`);
    }

    await this.vectorDB.delete(chunkIds);
    console.log('‚úÖ Document deleted');
  }
}

// Singleton instance
let ragServiceInstance: RAGService | null = null;

export function getRAGService(): RAGService {
  if (!ragServiceInstance) {
    ragServiceInstance = new RAGService();
  }
  return ragServiceInstance;
}
